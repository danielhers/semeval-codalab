<h1>Submissions</h1>
<p>Participants in the task submitted their results in the following format:</p>
<ul>
<li>One zip file including two main folders named "closed" and "open" - one for the closed tracks and the other for the open tracks.</li>
<li>Each directory should contain subfolder for each setting <span>they are participating at</span> and should be named accordingly.</li>
<ul>
<li>The options for settings are "<span>UCCA_English-Wiki</span>", "<span>UCCA_English-20K</span>", "<span>UCCA_German-20K</span>", "<span>UCCA_French-20K</span>".</li>
</ul>
<li>For example, the directory for UCCA_English-20K open track should be named "open/UCCA_English-20K".</li>
<li>Each track directory should contain file for each sentence with the predicted annotation, when the supported formats are <span>UCCA xml files, conllu, sdp and amr formats.</span></li>
</ul>
<p>Submit your system outputs <a href="19160#participate-submit_results" data-toggle="tab">here</a>.</p>
<h2><span style="font-size: 1.17em;">Results</span></h2>
<p dir="ltr"><span>The winners of the evaluation phase are:</span></p>
<p dir="ltr"><span>UCCA_English-Wiki_closed track: the winner is </span><strong>hlt@suda team</strong><span> with 0.774 labeled averaged F1 score.</span></p>
<p dir="ltr"><span>UCCA_English-Wiki_open track: the winner is </span><strong>hlt@suda team</strong><span> with 0.805 labeled averaged F1 score.</span></p>
<p dir="ltr"><span>UCCA_English-20K_closed track: the winner is </span><strong>hlt@suda team</strong><span> with 0.727 labeled averaged F1 score.</span></p>
<p dir="ltr"><span>UCCA_English-20K_open track: the winner is </span><strong>hlt@suda team</strong><span> with 0.767 labeled averaged F1 score.</span></p>
<p dir="ltr"><span>UCCA_German-20K_closed track: the winner is </span><strong>hlt@suda team</strong><span> with 0.832 labeled averaged F1 score.</span></p>
<p dir="ltr"><span>UCCA_German-20K_open track: the winner is </span><span><strong>hlt@suda</strong></span><span> with 0.849 labeled averaged F1 score.</span></p>
<p dir="ltr"><span>UCCA_French-20K_open track: the winner is </span><strong>hlt@suda</strong><span> with 0.752 labeled averaged F1 score.</span></p>
<p>The full results of the evaluation phase can be found <a href="https://docs.google.com/spreadsheets/d/1b3b5dKH18Qr0zHvPJdFP6KMMBU3jlKaRk_xYC5a7RjE/edit#gid=1292688781">here</a>.</p>
<p>The results of the post evaluation phase can be found <a href="https://docs.google.com/spreadsheets/d/10wwmK25w13VlkKXBasIS1JJS4K6vG8DII2Lt6DOR0aU/edit?usp=sharing">here.</a></p>
<h2>Baseline Models</h2>
<p>Baseline models are available <a href="http://www.cs.huji.ac.il/~danielh/ucca/baseline_models.zip">here</a>.</p>
<p>To run these models, first install tupa:</p>
<pre>pip install tupa==1.3.8</pre>
<p>Then run:</p>
<pre>python -m tupa &lt;DATA&gt; -m &lt;MODEL&gt; -o &lt;OUTDIR&gt;</pre>
<p>For example,</p>
<pre>python -m tupa dev/closed/UCCA_English-Wiki -m ucca-bilstm-20180917 -o out/closed/UCCA_English-Wiki</pre>
<p>These models are the baseline models for the following competition tracks:</p>
<table border="0">
<tbody>
<tr>
<td>ucca-bilstm-20180917</td>
<td>closed/UCCA_English-Wiki</td>
</tr>
<tr>
<td>ucca-bilstm-20180917</td>
<td>closed/UCCA_English-20K</td>
</tr>
<tr>
<td>ucca-de-bilstm-20180917</td>
<td>closed/UCCA_German-20K</td>
</tr>
<tr>
<td>ucca-amr-dm-ud-bilstm-20180917</td>
<td>open/UCCA_English-Wiki</td>
</tr>
<tr>
<td>ucca-amr-dm-ud-bilstm-20180917</td>
<td>open/UCCA_English-20K</td>
</tr>
<tr>
<td>ucca-ud-de-bilstm-20180917</td>
<td>open/UCCA_German-20K</td>
</tr>
<tr>
<td>ucca-ud-fr-bilstm-20180917</td>
<td>open/UCCA_French-20K</td>
</tr>
</tbody>
</table>